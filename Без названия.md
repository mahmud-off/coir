Что надо сделать до 18-го:

# 1 - полный пайплайн COIR'a изучить + оформить для других

# 2 - Структурирование всех экспериментов
- ## Получить метрики для семантического поиска (bge-m3, e5)
- ## Получить метрики для семантики + переписанных запросов (bge-m3, e5, <2-3 модельки на выбор>)
- ## Получить метрики для семантики + лексики (bge-m3, e5 * bm25)
- ## Получить метрики для лексического поиска
# 3 - PPTX или PNG схемка

--------------------------------------------------------------------------
**Гипотеза:** Почему-то не нагружается gpu при запуске на gpu, надо сравнить результаты на CPU и на GPU.
**Эксперимент**: Результат одинаковый.

------------------------------------------------------------------------
# Маленький экскурс по работе с COIR на своей машине (бесплатно)
1. установить AdGuard VPN
2. Если есть GPU
	1. из виртуального окружения:
	2. `pip uninstall torch`
	3. Установить с [pytorch.org](pytorch.org)
	4. Windows: `pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu126`
	5. Linux:`pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu126`
	6. Mac:`# CUDA is not available on MacOS, please use default packagepip3 install torch torchvision`
	7. После этого будет запускаться на GPU (я проверил)
3. можно работать с COIR
## Замечания
- VPN нужен только для скачивания моделек, по сути можно накачать модельки и работать без VPN
- Так же по моим наблюдениям, я заметил, что датасеты COIR'а скачиваются с haggin face и без VPN (значит можно запускать все дефолтные задачи без VPN)
- AdGuardVPN предоставляет 4Гб в месяц, переустановить один торч выйдет только в 2.6Гб, поэтому просто меняем почту и качаем модельки до 4ГБ
# Просто чтобы понимать, что такое COIR
*Picture_0*
![[pictures/Pasted image 20260112195750.png]]
## Поверхостный пайплайн COIR'а:
1. создать сущность модели (главный критерий модели чтобы её мог использовать COIR (BEIR) - `#model is class that provides encode_corpus() and encode_queries()`, [см_файл](obsidian://open?vault=Obsidian%20Vault&file=course_work%2FCOIR'S%20functionality))
2. распарсить задачки c датасета (по умолчанию с haggin face)
3. создать сущность бенчмарка, которому передаётся распаршенный датасет
4. в сущности бенчмарка реализована проверка (метод run *Picture_0*)
	1. проверка, нет ли уже существующего решения этой задачи
	2. инициализация модели, ретривера, и рассчет значений по задачам
	3. оценка по метрикам
	4. красивое оформление в json и вывод в файл

То есть по сути, о чем и говорил Вадим, у нас есть 3 сущности
- сущность `моделька`
- сущность `задача`
- сущность `оценщик`
**Что нам это даёт:**
3 очевидных вектора развития бенчмарка:
1. придумать интересную задачку со своим датасетом, то самое "чего нем в COIR" [см_файл](obsidian://open?vault=Obsidian%20Vault&file=course_work%2FCOIR'S%20functionality)
2. модернизировать пайплайн оценщика
3. 
## Глубинный "пайплайн" COIR'a
Глубинно разобрать:
- как происходит распарс задачек
- Как представляется выход модельки (в тех самых обязательных двух методах)
- как происходит работа оценщика -> По сути сводится к работе части BEIR'a (*Picture_0 выделено зелёным цветом*)

# Просто читал код и случайно понял как добавить свой датасет (распишу по шагам в Резюме)

Picture_1
![[pictures/Pasted image 20260112202734.png]]
Picture_2
![[pictures/Pasted image 20260112202747.png]]
## COIR подкачивает датасеты с HF Hub, причем работает это без vpn.
Picture_3
![[pictures/Pasted image 20260112202833.png]]
## Если в path передать локальный путь, то он распарсит его как датасет. 
Picture_4
![[pictures/Pasted image 20260112202943.png]]
Picture_5
![[pictures/Pasted image 20260112203018.png]]
## Есть пример от разработчиков как распарсить локальный датасет.
Picture_6
![[pictures/Pasted image 20260112203033.png]]
## Резюме
## Чтобы добавить свой датасет надо:
1. подготовить сам датасет (пока хз в каком он формате)
2. в функции `get_task()` *Picture_2* реализовать логику поиска задачи в локальных файлах
3. в по примеру функции `load_data_from_hf` *Picture_3* реализовать функцию `load_local_data` в которой функция `load_dataset` будет принимать локальный путь до датасета *Picture_5-6*. ЛИБО вмонтировать это в саму `load_data_from_hf`, чтобы избежать повторения кода. (НО из офиц примера видно, что надо будет дополнительно передавать параметр формата файла, можно сделать как дефолтный параметр)
## Замечание
По надо посмотреть как хранятся датасеты и можно будет попробовать добавить свой датасет. Ну и т.к не моя задача, пока только расписал, если потребуется, можно довести до ума.

